{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "def set_bnds_as_coords(ds):\n",
    "    new_coords_vars = [var for var in ds.data_vars if 'bnds' in var or 'bounds' in var]\n",
    "    ds = ds.set_coords(new_coords_vars)\n",
    "    return ds\n",
    "\n",
    "def read_codes(zarr):\n",
    "    dex = pd.read_csv('csv/exceptions.csv',skipinitialspace=True)\n",
    "    codes = []\n",
    "    [source_id,experiment_id,member_id,table_id,variable_id,grid_label] = zarr.split('/')\n",
    "    for ex in dex.values:\n",
    "        dd = dict(zip(dex.keys(),ex))\n",
    "        if dd['source_id'] == source_id or dd['source_id'] == 'all':\n",
    "            if dd['experiment_id'] == experiment_id or dd['experiment_id'] == 'all':\n",
    "                if dd['member_id'] == member_id or dd['member_id'] == 'all':\n",
    "                    if dd['table_id'] == table_id or dd['table_id'] == 'all':\n",
    "                        if dd['variable_id'] == variable_id or dd['variable_id'] == 'all':\n",
    "                            if dd['grid_label'] == grid_label or dd['grid_label'] == 'all':                                 \n",
    "                                codes += [dd['reason_code']]\n",
    "                                print('special treatment needed:',dd['reason_code'])\n",
    "    return codes\n",
    "\n",
    "def get_new(ds, skip_sites, okay, trouble): \n",
    "    # download any files needed for this zarr store (or abort the attempt)\n",
    "    tmp = 'nctemp'\n",
    "    \n",
    "    files = ds[ds.zarr_name == zarr].file_name.unique()\n",
    "    gfiles = []\n",
    "    #urls = []\n",
    "    for file in files:\n",
    "        if okay:\n",
    "            save_file = tmp + '/'+file\n",
    "            expected_size = ds[ds.file_name == file]['size'].values[0]\n",
    "            if os.path.isfile(save_file):\n",
    "                if abs(os.path.getsize(save_file) - expected_size) <= 1000 :\n",
    "                    print('already have: ',save_file)\n",
    "                    gfiles += [save_file]\n",
    "                    continue\n",
    "\n",
    "            url = ds[ds.file_name == file].HTTPServer_url.values[0]\n",
    "            \n",
    "            for site in skip_sites:\n",
    "                if site in url:\n",
    "                    print('skip ',site,'domain for now')\n",
    "                    trouble[zarr] = 'skipping ' + site + ' domain'\n",
    "                    okay = False\n",
    "            \n",
    "            if not okay:\n",
    "                continue\n",
    "                \n",
    "            command = 'curl ' + url + ' -o ' + save_file\n",
    "            print(command)\n",
    "            os.system(command)\n",
    "\n",
    "            if os.path.getsize(save_file) != expected_size:\n",
    "                print('trying curl command again')\n",
    "                os.system(command)\n",
    "                if os.path.getsize(save_file) != expected_size:\n",
    "                    print('second download did not fix issue - skipping file:',file)\n",
    "                    trouble[zarr] = 'netcdf download not complete'\n",
    "                    okay = False\n",
    "            if os.path.getsize(save_file) == 0:\n",
    "                os.system(\"rm -f \"+save_file)\n",
    "            if okay:\n",
    "                gfiles += [save_file]\n",
    "    return gfiles\n",
    "\n",
    "def get_size(start_path = '.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def getsheet(json_keyfile,sheet_name):\n",
    "    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile, scope)\n",
    "\n",
    "    gc = gspread.authorize(credentials)\n",
    "\n",
    "    wks = gc.open(sheet_name).sheet1\n",
    "\n",
    "    data = wks.get_all_values()\n",
    "    headers = data.pop(0)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    df['experiments'] = [s.replace('*','').replace(' ','').split(',') for s in df.experiment_ids.values]\n",
    "    df['models'] = [s.replace('All Available','All').replace(' ','').split(',') for s in df.source_ids.values]\n",
    "    df['variables'] = [s.replace(' ','').split(',') for s in df['variable_ids (comma separated list)'].values]\n",
    "    df['table'] = [s.replace(' ','').split(':')[0] for s in df.table_id.values]\n",
    "    df['requester'] = df['Your name'] \n",
    "    df['status'] = df['LDEO status'] \n",
    "\n",
    "    df = df.drop(['Your name', 'Science Question/Motivation','Have you verified the existence of the data you will request?',\n",
    "                  'table_id', 'source_ids', 'experiment_ids','variable_ids (comma separated list)', 'Questions and comments', 'status'],1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def requests(): \n",
    "    json_keyfile = '/home/nhn2/json/Pangeo Hackathon-e48a41b13c91.json'\n",
    "    sheet_name = \"CMIP6 Hackathon Data Request (Responses)\"\n",
    "\n",
    "    df_all = getsheet(json_keyfile, sheet_name)\n",
    "    df_all.to_csv('csv/dummy.csv',index=False)\n",
    "    df_all = pd.read_csv('csv/dummy.csv')\n",
    "      \n",
    "    df_prior = pd.read_csv('csv/requests.csv')    \n",
    "    \n",
    "    df_new = df_all.merge(df_prior, how='left', indicator=True)\n",
    "    df_new = df_new[df_new['_merge']=='left_only'].drop('_merge',1)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def set_request_id():\n",
    "    return datetime.now().strftime('%Y%m-%d%H-%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(server, df_req):\n",
    "    df_list = []\n",
    "    for index, row in df_req.iterrows():\n",
    "        timestamp = row['Timestamp']\n",
    "        name = row['requester']\n",
    "        email = row['E-mail']\n",
    "        experiment_ids = ast.literal_eval(row['experiments'])\n",
    "        source_ids = ast.literal_eval(row['models'])\n",
    "        variable_ids = ast.literal_eval(row['variables'])\n",
    "        table_id = row['table']  \n",
    "        print(email)\n",
    "        for experiment_id in experiment_ids:\n",
    "            for variable_id in variable_ids:\n",
    "                print(experiment_id, variable_id, table_id, source_ids)\n",
    "                if source_ids[0] == 'All':\n",
    "                    try:\n",
    "                        files= my_search.esgf_search(server=server, mip_era='CMIP6', variable_id=variable_id, \n",
    "                                table_id=table_id, experiment_id=experiment_id, page_size=500, verbose=False)\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    files.loc[:,'version'] = [str.split('/')[-2] for str in files['HTTPServer_url']]\n",
    "                    files.loc[:,'file_name'] = [str.split('/')[-1] for str in files['HTTPServer_url']]\n",
    "                    # might need to set activity_id to activity_drs for some files (see old versions)\n",
    "                    files.loc[:,'activity_id'] = files.activity_drs\n",
    "\n",
    "                    df_list += [files.drop_duplicates(subset =[\"file_name\",\"version\",\"checksum\"]) ]\n",
    "                else:\n",
    "                    for source_id in source_ids:\n",
    "                        try:\n",
    "                            files= my_search.esgf_search(server=server, mip_era='CMIP6', variable_id=variable_id, \n",
    "                                    table_id=table_id, experiment_id=experiment_id, source_id = source_id, page_size=500, verbose=False)\n",
    "                        except:\n",
    "                            continue\n",
    "                            \n",
    "                        files.loc[:,'version'] = [str.split('/')[-2] for str in files['HTTPServer_url']]\n",
    "                        files.loc[:,'file_name'] = [str.split('/')[-1] for str in files['HTTPServer_url']]\n",
    "                        # might need to set activity_id to activity_drs for some files (see old versions)\n",
    "                        files.loc[:,'activity_id'] = files.activity_drs\n",
    "                        \n",
    "                        df_list += [files.drop_duplicates(subset =[\"file_name\",\"version\",\"checksum\"]) ]\n",
    "\n",
    "    dESGF = pd.concat(df_list,sort=False)\n",
    "    dESGF = dESGF.drop_duplicates(subset =[\"file_name\",\"version\",\"checksum\"])\n",
    "    keys_all = list(dESGF.keys())\n",
    "    keys_show = ['activity_drs','institution_id',\"source_id\",\"experiment_id\",\"member_id\",\"table_id\",\"variable_id\",'grid_label',\"file_name\",'HTTPServer_url']\n",
    "    keys_drop = list(set(keys_all) - set(keys_show))\n",
    "    return dESGF.drop(keys_drop,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify(dfm, df_req, dESGF):\n",
    "    single_member = single_member_tables\n",
    "\n",
    "    zarr_format = '/%(activity_drs)s/%(institution_id)s/%(source_id)s/%(experiment_id)s/%(member_id)s/%(table_id)s/%(variable_id)s/%(grid_label)s'\n",
    "    df_list = []\n",
    "    for index, row in df_req.iterrows():\n",
    "        timestamp = row['Timestamp']\n",
    "        name = row['requester']\n",
    "        email = row['E-mail']\n",
    "        experiment_ids = ast.literal_eval(row['experiments'])\n",
    "        source_ids = ast.literal_eval(row['models'])\n",
    "        variable_ids = ast.literal_eval(row['variables'])\n",
    "        table_id = row['table']\n",
    "        \n",
    "        for experiment_id in experiment_ids:\n",
    "            for variable_id in variable_ids:\n",
    "                for source_id in source_ids:\n",
    "                    df = dESGF[(dESGF.experiment_id==experiment_id)&(dESGF.table_id==table_id)&\n",
    "                               (dESGF.variable_id==variable_id)    &(dESGF.source_id==source_id)]\n",
    "                    member_ids = df.member_id.unique()\n",
    "                    for member_id in member_ids:\n",
    "                        dfm = df[df.member_id==member_id]\n",
    "                        file=dfm.values[0]\n",
    "                        zarr_dir = dict(zip(df.keys(),file))\n",
    "                        zarr_file = zarr_format % zarr_dir\n",
    "                        dfm.loc[:,'zstore'] = zarr_file\n",
    "                        df_list += [dfm]\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HTTPServer_url', 'activity_drs', 'experiment_id', 'grid_label',\n",
       "       'institution_id', 'member_id', 'source_id', 'table_id', 'variable_id',\n",
       "       'file_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dESGF.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import my_search\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cmip6-master.csv \n",
    "#url_cloud = 'https://storage.googleapis.com/cmip6/cmip6.csv'\n",
    "#df = pd.read_csv(url_cloud)\n",
    "#df.to_csv('csv/cmip6-master.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {}\n",
    "dtype['llnl'] = \"https://esgf-node.llnl.gov/esg-search/search\"\n",
    "dtype['ipsl'] = \"https://esgf-node.ipsl.upmc.fr/esg-search/search\"\n",
    "dtype['nci']  = \"https://esgf.nci.org.au/esg-search/search\"  \n",
    "dtype['ceda'] = \"https://esgf-index1.ceda.ac.uk/esg-search/search\"   # nothing yet\n",
    "dtype['jpl'] = \"https://esgf-node.jpl.nasa.gov/esg-search/search\"   # connection refused\n",
    "dtype['gfdl'] =  \"https://esgdata.gfdl.noaa.gov/esg-search/search\"    # only amip and piControl\n",
    "dtype['dkrz'] =  \"https://esgf-data.dkrz.de/esg-search/search\"        # no historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some choices\n",
    "ESGF_site = dtype['llnl']\n",
    "skip_sites = ['dist.nmlab.snu.ac.kr','esg.lasg.ac.cn','esgf-data2.diasjp.net']\n",
    "single_member_tables = ['Omon', 'CF3hr','3hr','E3hr', '6hrLev', 'day', '6hrPlev', '6hrPlevPt', 'fx', 'Ofx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv/exceptions_201911-0907-5418.csv csv/cmip6_201911-0907-5418.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>E-mail</th>\n",
       "      <th>LDEO status</th>\n",
       "      <th>hackathon location</th>\n",
       "      <th>experiments</th>\n",
       "      <th>models</th>\n",
       "      <th>variables</th>\n",
       "      <th>table</th>\n",
       "      <th>requester</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>11/8/2019 11:44:12</td>\n",
       "      <td>test@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['historical']</td>\n",
       "      <td>['CESM2']</td>\n",
       "      <td>['ts', 'tas']</td>\n",
       "      <td>Amon</td>\n",
       "      <td>Naomi Henderson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp          E-mail LDEO status hackathon location  \\\n",
       "66  11/8/2019 11:44:12  test@gmail.com         NaN                NaN   \n",
       "\n",
       "       experiments     models      variables table        requester  \n",
       "66  ['historical']  ['CESM2']  ['ts', 'tas']  Amon  Naomi Henderson  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_request_new = requests()\n",
    "request_id = set_request_id()\n",
    "\n",
    "c_file = 'csv/cmip6_'+request_id+'.csv'\n",
    "x_file = 'csv/exceptions_'+request_id+'.txt'\n",
    "\n",
    "print(x_file,c_file)\n",
    "df_request_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://esgf-node.llnl.gov/esg-search/search\n",
      "test@gmail.com\n",
      "historical ts Amon ['CESM2']\n",
      "historical tas Amon ['CESM2']\n"
     ]
    }
   ],
   "source": [
    "print(ESGF_site)\n",
    "df_ESGF = search(ESGF_site,df_request_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('csv/cmip6-master.csv')\n",
    "df_needed = identify(df_master, df_request_new, df_ESGF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>date_start</th>\n",
       "      <th>date_stop</th>\n",
       "      <th>time_len</th>\n",
       "      <th>sizeG</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [activity_id, institution_id, source_id, experiment_id, member_id, table_id, variable_id, grid_label, zstore, date_start, date_stop, time_len, sizeG, dcpp_init_year]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_master[df_master.table_id=='junk']\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HTTPServer_url</th>\n",
       "      <th>activity_drs</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>zstore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://aims3.llnl.gov/thredds/fileServer/css03...</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "      <td>gn</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>Amon</td>\n",
       "      <td>ts</td>\n",
       "      <td>ts_Amon_CESM2_historical_r10i1p1f1_gn_185001-1...</td>\n",
       "      <td>/CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://aims3.llnl.gov/thredds/fileServer/css03...</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "      <td>gn</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>Amon</td>\n",
       "      <td>ts</td>\n",
       "      <td>ts_Amon_CESM2_historical_r10i1p1f1_gn_190001-1...</td>\n",
       "      <td>/CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://aims3.llnl.gov/thredds/fileServer/css03...</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "      <td>gn</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>Amon</td>\n",
       "      <td>ts</td>\n",
       "      <td>ts_Amon_CESM2_historical_r10i1p1f1_gn_195001-1...</td>\n",
       "      <td>/CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>http://aims3.llnl.gov/thredds/fileServer/css03...</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "      <td>gn</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>Amon</td>\n",
       "      <td>ts</td>\n",
       "      <td>ts_Amon_CESM2_historical_r10i1p1f1_gn_200001-2...</td>\n",
       "      <td>/CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>http://aims3.llnl.gov/thredds/fileServer/css03...</td>\n",
       "      <td>CMIP</td>\n",
       "      <td>historical</td>\n",
       "      <td>gn</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>r11i1p1f1</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>Amon</td>\n",
       "      <td>ts</td>\n",
       "      <td>ts_Amon_CESM2_historical_r11i1p1f1_gn_185001-1...</td>\n",
       "      <td>/CMIP/NCAR/CESM2/historical/r11i1p1f1/Amon/ts/gn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       HTTPServer_url activity_drs  \\\n",
       "0   http://aims3.llnl.gov/thredds/fileServer/css03...         CMIP   \n",
       "6   http://aims3.llnl.gov/thredds/fileServer/css03...         CMIP   \n",
       "12  http://aims3.llnl.gov/thredds/fileServer/css03...         CMIP   \n",
       "18  http://aims3.llnl.gov/thredds/fileServer/css03...         CMIP   \n",
       "24  http://aims3.llnl.gov/thredds/fileServer/css03...         CMIP   \n",
       "\n",
       "   experiment_id grid_label institution_id  member_id source_id table_id  \\\n",
       "0     historical         gn           NCAR  r10i1p1f1     CESM2     Amon   \n",
       "6     historical         gn           NCAR  r10i1p1f1     CESM2     Amon   \n",
       "12    historical         gn           NCAR  r10i1p1f1     CESM2     Amon   \n",
       "18    historical         gn           NCAR  r10i1p1f1     CESM2     Amon   \n",
       "24    historical         gn           NCAR  r11i1p1f1     CESM2     Amon   \n",
       "\n",
       "   variable_id                                          file_name  \\\n",
       "0           ts  ts_Amon_CESM2_historical_r10i1p1f1_gn_185001-1...   \n",
       "6           ts  ts_Amon_CESM2_historical_r10i1p1f1_gn_190001-1...   \n",
       "12          ts  ts_Amon_CESM2_historical_r10i1p1f1_gn_195001-1...   \n",
       "18          ts  ts_Amon_CESM2_historical_r10i1p1f1_gn_200001-2...   \n",
       "24          ts  ts_Amon_CESM2_historical_r11i1p1f1_gn_185001-1...   \n",
       "\n",
       "                                              zstore  \n",
       "0   /CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn  \n",
       "6   /CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn  \n",
       "12  /CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn  \n",
       "18  /CMIP/NCAR/CESM2/historical/r10i1p1f1/Amon/ts/gn  \n",
       "24  /CMIP/NCAR/CESM2/historical/r11i1p1f1/Amon/ts/gn  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-Oct2019",
   "language": "python",
   "name": "pangeo-oct2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
