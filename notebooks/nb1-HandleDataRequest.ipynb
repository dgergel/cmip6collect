{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import qgrid\n",
    "import gcsfs\n",
    "import xarray as xr\n",
    "\n",
    "from request import requests, set_request_id, get_ncfiles, concatenate\n",
    "from search import search, esgf_search_sites\n",
    "from identify import identify\n",
    "from response import response, dict_to_dfcat, get_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cmip6-master.csv \n",
    "#url_cloud = 'https://storage.googleapis.com/cmip6/cmip6.csv'\n",
    "#df = pd.read_csv(url_cloud)\n",
    "#df.to_csv('csv/cmip6-master.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some choices\n",
    "dtype = esgf_search_sites()\n",
    "ESGF_site = dtype['llnl']\n",
    "skip_sites = ['dist.nmlab.snu.ac.kr','esg.lasg.ac.cn','esgf-data2.diasjp.net']\n",
    "#single_member_tables = ['Omon', 'CF3hr','3hr','E3hr', '6hrLev', 'day', '6hrPlev', '6hrPlevPt', 'fx', 'Ofx']\n",
    "single_member_tables = ['fx', 'Ofx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get any new requests\n",
    "df_request_new = requests()\n",
    "request_id = set_request_id()\n",
    "\n",
    "c_file = 'csv/cmip6_'+request_id+'.csv'\n",
    "x_file = 'csv/exceptions_'+request_id+'.txt'\n",
    "\n",
    "df_request_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search ESGF for the availability of requested data\n",
    "df_ESGF = search(ESGF_site,df_request_new)\n",
    "len(df_ESGF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qgrid.show_grid(df_ESGF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('csv/cmip6-master.csv')\n",
    "#qgrid.show_grid(df_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_needed = identify(df_master, df_request_new, df_ESGF, single_member_tables)\n",
    "#qgrid.show_grid(df_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_needed) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIG LOOP  (zarr by zarr - can do in parallel)\n",
    "\n",
    "\n",
    "print('number of files needed',len(df_needed))\n",
    "print('number of stores to be created',df_needed.zstore.nunique())\n",
    "\n",
    "new_zarrs = df_needed.zstore.unique()\n",
    "\n",
    "zdict = {}\n",
    "for item,zarr in enumerate(new_zarrs):\n",
    "\n",
    "    # does it exist in ztemp already?\n",
    "    zbdir  = 'ztemp'  + zarr\n",
    "    if os.path.isfile(zbdir+'/.zmetadata'):\n",
    "        print(item,'already exists:',zbdir)\n",
    "        #continue\n",
    "\n",
    "    gfiles = get_ncfiles(zarr,df_needed,skip_sites)\n",
    "    if len(gfiles) == 0: \n",
    "        print(item,'no files available')\n",
    "        continue\n",
    "        \n",
    "    # concatenate in time with mfdataset\n",
    "    status, ds, ddict = concatenate(zarr,gfiles)  \n",
    "\n",
    "    if status == 'failure':\n",
    "        print(item,'oops, no dice')\n",
    "        continue\n",
    "\n",
    "    #ds.to_zarr(zbdir, consolidated=True, mode='w')  \n",
    "\n",
    "    if not os.path.isfile(zbdir+'/.zmetadata'):\n",
    "        continue\n",
    "   \n",
    "    gsurl, vlist = get_details(ds,zbdir,zarr)\n",
    "    \n",
    "    # remove netcdf files\n",
    "    #for gfile in gfiles:\n",
    "    #   os.system('rm -f '+ gfile)\n",
    "    print(item,'successfully saved as ',zbdir) \n",
    "    \n",
    "    # upload to cloud\n",
    "    contents = fs.ls(gsurl+'/.zmetadata')\n",
    "    if any(\"zmetadata\" in s for s in contents):\n",
    "        print(item,'store already in cloud')\n",
    "    else:\n",
    "        command = '/usr/bin/gsutil -m cp -r '+ zbdir + ' ' + gsurl\n",
    "        print(command)\n",
    "        #os.system(command) \n",
    "    print(gsurl)    \n",
    "    try:\n",
    "        ds = xr.open_zarr(fs.get_mapper(gsurl), consolidated=True)\n",
    "        zdict[item] = vlist\n",
    "    except:\n",
    "        print('store did not get saved properly')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = dict_to_dfcat(zdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_new = pd.concat([df_master, dz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response(df_request_new,df_master_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-Oct2019",
   "language": "python",
   "name": "pangeo-oct2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
