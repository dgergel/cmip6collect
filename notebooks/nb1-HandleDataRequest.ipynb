{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Handle New Data Requests Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gcsfs\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from request import requests, set_request_id\n",
    "from search import search, esgf_search_sites\n",
    "from netcdf import get_ncfiles, concatenate\n",
    "from identify import needed\n",
    "from response import response, dict_to_dfcat, get_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only')\n",
    "\n",
    "# ONLY WHEN NECESSARY: Re-initialize cmip6-master.csv with enhanced csv file\n",
    "#url_cloud = 'https://storage.googleapis.com/cmip6/cmip6.csv'  \n",
    "#df = pd.read_csv(url_cloud)\n",
    "#df.to_csv('csv/cmip6-master.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible ESGF API search nodes:  ['llnl', 'ipsl', 'nci', 'ceda', 'jpl', 'gfdl', 'dkrz']\n"
     ]
    }
   ],
   "source": [
    "dtype = esgf_search_sites()\n",
    "print('possible ESGF API search nodes: ',list(dtype.keys()))\n",
    "ESGF_site = dtype['llnl']\n",
    "\n",
    "# Skip the following sites for getting netcdf files: broken or slow sites\n",
    "skip_sites = ['dist.nmlab.snu.ac.kr','esg.lasg.ac.cn','esgf-data2.diasjp.net']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get new Google Sheet requests, open some log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 naomi@ldeo.columbia.edu []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list(['All'])], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_request_new = requests()\n",
    "request_id = set_request_id()\n",
    "file_cat = 'csv/cmip6_'+request_id+'.csv'\n",
    "file_x = 'txt/exceptions_'+request_id+'.txt'\n",
    "file_log = 'txt/request_'+request_id+'.log'\n",
    "\n",
    "f_cat = open(file_cat,'w')\n",
    "f_x = open(file_x,'w')\n",
    "f_log = open(file_log,'w')\n",
    "\n",
    "df_request_new.members.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search ESGF for the availability of requested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naomi@ldeo.columbia.edu\n",
      "IfxGre hfgeoubed ['All'] ['All']\n",
      "IfxGre lithk ['All'] ['All']\n",
      "IfxGre topg ['All'] ['All']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ESGF = search(ESGF_site,df_request_new)\n",
    "len(df_ESGF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.read_csv('csv/cmip6-master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_needed = needed(df_master, df_request_new, df_ESGF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files needed 89\n",
      "number of stores to be created 89\n"
     ]
    }
   ],
   "source": [
    "print('number of files needed',len(df_needed))\n",
    "num_stores = df_needed.zstore.nunique() \n",
    "print('number of stores to be created',num_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop if there is nothing to do\n",
    "assert len(df_needed) >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### The work is done in this next loop - can be done in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "new_zarrs = df_needed.zstore.unique()\n",
    "\n",
    "zdict = {}  # construct dictionary for new rows to add to master catalog\n",
    "for item,zarr in enumerate(new_zarrs):\n",
    "    #zbdir  = 'ztemp'  + zarr\n",
    "    zbdir  = '/d5/naomi/zarr-minimal'  + zarr\n",
    "    \n",
    "    print(f\"{item}/{num_stores}: local file: {zbdir}\")\n",
    "    \n",
    "    # does it exist in ztemp already?\n",
    "    if os.path.isfile(zbdir+'/.zmetadata'):\n",
    "        print(item,'already exists:',zbdir)\n",
    "        continue\n",
    "\n",
    "    gfiles = get_ncfiles(zarr,df_needed,skip_sites)\n",
    "    if len(gfiles) == 0: \n",
    "        print(item,'no files available')\n",
    "        continue\n",
    "    \n",
    "    variable_id = zarr.split('/')[-2]\n",
    "    for gfile in gfiles:   # changes file sizes!!\n",
    "        command = '/usr/bin/ncatted -h -O -a missing_value\\,'+variable_id+',d,, '+gfile\n",
    "        os.system(command)\n",
    "    \n",
    "    # concatenate in time with mfdataset\n",
    "    status, ds, ddict = concatenate(zarr,gfiles)  \n",
    "\n",
    "    if status == 'failure':\n",
    "        print(item,'oops, no dice')\n",
    "        continue\n",
    "\n",
    "    ds.to_zarr(zbdir, consolidated=True, mode='w')  \n",
    "\n",
    "    if not os.path.isfile(zbdir+'/.zmetadata'):\n",
    "        print('to_zarr failure')\n",
    "        continue\n",
    "   \n",
    "    gsurl, vlist = get_details(ds,zbdir,zarr)\n",
    "    \n",
    "    # upload to cloud\n",
    "    contents = fs.ls(gsurl+'/.zmetadata')\n",
    "    if any(\"zmetadata\" in s for s in contents):\n",
    "        print(item,'store already in cloud')\n",
    "        continue\n",
    "    else:\n",
    "        command = '/usr/bin/gsutil -m cp -r '+ zbdir + ' ' + gsurl\n",
    "        print(command)\n",
    "        os.system(command) \n",
    "        \n",
    "    try:\n",
    "        ds = xr.open_zarr(fs.get_mapper(gsurl), consolidated=True)\n",
    "        zdict[item] = vlist\n",
    "        print(item,'successfully saved as ',zbdir) \n",
    "        for gfile in gfiles:\n",
    "           os.system('rm -f '+ gfile)\n",
    "    except:\n",
    "        print('store did not get saved to GCS properly')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = dict_to_dfcat(zdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_new = pd.concat([df_master, dz])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a table of aquired data to send in email to requestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS request for: naomi@ldeo.columbia.edu ; table_id= IfxGre\n",
      "(number of member_ids)*(number of grid_labels)\n",
      "--------------------------\n",
      "variable_id                hfgeoubed  lithk  topg\n",
      "experiment_id source_id                          \n",
      "1pctCO2       CESM2                1      1     1\n",
      "              CESM2-WACCM          1      1     1\n",
      "amip          CESM2                3      3     3\n",
      "              CESM2-WACCM          3      3     2\n",
      "esm-hist      CESM2                2      0     1\n",
      "esm-piControl CESM2                1      1     1\n",
      "historical    CESM2               11     11    11\n",
      "              CESM2-WACCM          3      3     3\n",
      "lig127k       CESM2                1      1     1\n",
      "piControl     CESM2                1      1     1\n",
      "              CESM2-WACCM          1      1     1\n",
      "ssp585        CESM2                2      2     2\n",
      "              CESM2-WACCM          1      1     1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response(df_request_new,df_master_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-Oct2019",
   "language": "python",
   "name": "pangeo-oct2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
